{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Docling Hybrid Chunking 教程\n",
        "\n",
        "参考文档：[Hybrid chunking（Docling 官方示例）](https://docling-project.github.io/docling/examples/hybrid_chunking/)\n",
        "\n",
        "本笔记本演示：\n",
        "- 使用 `DocumentConverter` 转换文档\n",
        "- 使用 `HybridChunker` 进行混合分块\n",
        "- 使用 `contextualize()` 生成上下文增强文本\n",
        "- 可选：与 HuggingFace 分词器对齐，保持与嵌入模型一致\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "DATA_PATH = Path(\"tutorial/hybrid_chunking/data/wiki.md\").resolve()\n",
        "print(\"DATA_PATH:\", DATA_PATH)\n",
        "assert DATA_PATH.exists(), f\"Sample data not found: {DATA_PATH}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 如果尚未安装，请取消注释以下命令\n",
        "# %pip install -qU docling transformers\n",
        "\n",
        "from docling.document_converter import DocumentConverter\n",
        "\n",
        "doc = DocumentConverter().convert(source=str(DATA_PATH)).document\n",
        "print(type(doc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from docling.chunking import HybridChunker\n",
        "\n",
        "chunker = HybridChunker()\n",
        "chunks = list(chunker.chunk(dl_doc=doc))\n",
        "print(f\"num_chunks: {len(chunks)}\")\n",
        "\n",
        "for i, chunk in enumerate(chunks[:5]):\n",
        "    original = chunk.text or \"\"\n",
        "    enriched = chunker.contextualize(chunk=chunk)\n",
        "    print(f\"\\n=== {i} ===\")\n",
        "    print(\"chunk.text:\\n\" + (original[:500] + (\"…\" if len(original) > 500 else \"\")))\n",
        "    print(\"\\nchunker.contextualize(chunk):\\n\" + (enriched[:500] + (\"…\" if len(enriched) > 500 else \"\")))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 提示：使用 `HybridChunker` 时，transformers 可能会打印“序列长度超限”的警告，但在本场景通常是“误报”。详情可见官方示例链接。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 与 HF 分词器对齐（可选）：在 RAG 中建议与嵌入模型保持一致\n",
        "from typing import Optional\n",
        "try:\n",
        "    from transformers import AutoTokenizer\n",
        "except Exception:\n",
        "    AutoTokenizer = None\n",
        "\n",
        "hf_model_name: Optional[str] = \"sentence-transformers/all-MiniLM-L6-v2\"  # 可按需替换\n",
        "\n",
        "tokenizer = None\n",
        "if AutoTokenizer is not None and hf_model_name:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(hf_model_name, use_fast=True)\n",
        "\n",
        "chunker_with_tok = HybridChunker(tokenizer=tokenizer) if tokenizer else HybridChunker()\n",
        "chunks_tok = list(chunker_with_tok.chunk(dl_doc=doc))\n",
        "print(f\"num_chunks (tokenizer={bool(tokenizer)}): {len(chunks_tok)}\")\n",
        "\n",
        "for i, chunk in enumerate(chunks_tok[:3]):\n",
        "    orig = chunk.text or \"\"\n",
        "    enriched = chunker_with_tok.contextualize(chunk=chunk)\n",
        "    print(f\"\\n=== {i} (with tokenizer) ===\")\n",
        "    print(\"chunk.text:\\n\" + (orig[:300] + (\"…\" if len(orig) > 300 else \"\")))\n",
        "    print(\"\\ncontextualized:\\n\" + (enriched[:300] + (\"…\" if len(enriched) > 300 else \"\")))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
